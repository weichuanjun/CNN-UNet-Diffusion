{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, ReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# tensorboard --logdir logs/fit\n",
    "\n",
    "# 定义 TensorBoard 日志目录\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "# 扩散模型生成网络\n",
    "def build_simple_diffusion_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    outputs = Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "    return Model(inputs, outputs, name=\"simple_diffusion_model\")\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "diffusion_model = build_simple_diffusion_model(input_shape)\n",
    "diffusion_model.summary()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "diffusion_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 打印模型输入输出形状\n",
    "print(\"模型输入形状:\", diffusion_model.input_shape)\n",
    "print(\"模型输出形状:\", diffusion_model.output_shape)\n",
    "\n",
    "# 使用ImageDataGenerator加载数据\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2  # 设置验证集比例\n",
    ")\n",
    "\n",
    "# 生成训练数据\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='training'  # 设置为训练数据\n",
    ")\n",
    "\n",
    "# 生成验证数据\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='validation'  # 设置为验证数据\n",
    ")\n",
    "\n",
    "# 检查生成器是否正确生成数据\n",
    "print(\"检查训练数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(train_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(\"检查验证数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(validation_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(f\"训练数据的batch size: {train_generator.batch_size}\")\n",
    "print(f\"验证数据的batch size: {validation_generator.batch_size}\")\n",
    "\n",
    "# 自定义回调函数以记录每一层的输出\n",
    "class LayerOutputLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, generator):\n",
    "        super(LayerOutputLogger, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.generator = generator\n",
    "        self.file_writers = {}\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(LayerOutputLogger, self).set_model(model)\n",
    "        for layer in self.model.layers:\n",
    "            if 'conv' in layer.name or 'relu' in layer.name or 'batch_normalization' in layer.name:\n",
    "                self.file_writers[layer.name] = tf.summary.create_file_writer(os.path.join(self.log_dir, layer.name))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            x_batch, _ = next(self.generator)\n",
    "            sample = x_batch[0:1]  # 选择一个样本\n",
    "            for layer_name, file_writer in self.file_writers.items():\n",
    "                layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer(layer_name).output)\n",
    "                feature_maps = layer_model.predict(sample)\n",
    "                with file_writer.as_default():\n",
    "                    for i in range(min(feature_maps.shape[-1], 3)):  # 只记录前三个特征图\n",
    "                        tf.summary.image(f\"{layer_name}_filter_{i}\", feature_maps[..., i:i+1], step=epoch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LayerOutputLogger on_epoch_end: {e}\")\n",
    "\n",
    "# 定义训练参数\n",
    "epochs = 10\n",
    "\n",
    "# 训练模型\n",
    "history = diffusion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[tensorboard_callback, LayerOutputLogger(log_dir, train_generator)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 生成新样本\n",
    "noise = np.random.normal(0, 1, (10, 64, 64, 3))\n",
    "generated_images = diffusion_model.predict(noise)\n",
    "\n",
    "# 显示生成的图片\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印训练历史\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, ReLU, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义 TensorBoard 日志目录\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "# 定义更复杂的扩散模型生成网络\n",
    "def build_complex_diffusion_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=2, padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "    return Model(inputs, outputs, name=\"complex_diffusion_model\")\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "diffusion_model = build_complex_diffusion_model(input_shape)\n",
    "diffusion_model.summary()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "diffusion_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 打印模型输入输出形状\n",
    "print(\"模型输入形状:\", diffusion_model.input_shape)\n",
    "print(\"模型输出形状:\", diffusion_model.output_shape)\n",
    "\n",
    "# 使用ImageDataGenerator加载数据\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2  # 设置验证集比例\n",
    ")\n",
    "\n",
    "# 生成训练数据\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='training',  # 设置为训练数据\n",
    "    classes=['cats'] \n",
    ")\n",
    "\n",
    "# 生成验证数据\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='validation' , # 设置为验证数据\n",
    "    classes=['cats'] \n",
    ")\n",
    "\n",
    "# 检查生成器是否正确生成数据\n",
    "print(\"检查训练数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(train_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(\"检查验证数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(validation_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(f\"训练数据的batch size: {train_generator.batch_size}\")\n",
    "print(f\"验证数据的batch size: {validation_generator.batch_size}\")\n",
    "\n",
    "# 自定义回调函数以记录每一层的输出\n",
    "class LayerOutputLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, generator):\n",
    "        super(LayerOutputLogger, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.generator = generator\n",
    "        self.file_writers = {}\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(LayerOutputLogger, self).set_model(model)\n",
    "        for layer in self.model.layers:\n",
    "            if 'conv' in layer.name or 'relu' in layer.name or 'batch_normalization' in layer.name:\n",
    "                self.file_writers[layer.name] = tf.summary.create_file_writer(os.path.join(self.log_dir, layer.name))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            x_batch, _ = next(self.generator)\n",
    "            sample = x_batch[0:1]  # 选择一个样本\n",
    "            for layer_name, file_writer in self.file_writers.items():\n",
    "                layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer(layer_name).output)\n",
    "                feature_maps = layer_model.predict(sample)\n",
    "                with file_writer.as_default():\n",
    "                    for i in range(min(feature_maps.shape[-1], 3)):  # 只记录前三个特征图\n",
    "                        tf.summary.image(f\"{layer_name}_filter_{i}\", feature_maps[..., i:i+1], step=epoch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LayerOutputLogger on_epoch_end: {e}\")\n",
    "\n",
    "# 定义训练参数\n",
    "epochs = 50\n",
    "\n",
    "# 训练模型\n",
    "history = diffusion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[tensorboard_callback, LayerOutputLogger(log_dir, train_generator)]\n",
    ")\n",
    "\n",
    "# 启动TensorBoard（在命令行中运行）\n",
    "# !tensorboard --logdir logs/fit\n",
    "\n",
    "# 生成新样本\n",
    "noise = np.random.normal(0, 1, (10, 64, 64, 3))\n",
    "generated_images = diffusion_model.predict(noise)\n",
    "\n",
    "# 显示生成的图片\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印训练历史\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成新样本\n",
    "noise = np.random.normal(0, 2, (10, 64, 64, 3))\n",
    "generated_images = diffusion_model.predict(noise)\n",
    "\n",
    "# 显示生成的图片\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"diffusion_model.keras\"\n",
    "diffusion_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 加载模型\n",
    "model_load_path = \"./DATA/model/diffusion_model.keras\"\n",
    "loaded_model = load_model(model_load_path)\n",
    "print(f\"Model loaded from {model_load_path}\")\n",
    "\n",
    "# 确认模型架构\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, ReLU, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义 TensorBoard 日志目录\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "# 定义更复杂的扩散模型生成网络\n",
    "def build_complex_diffusion_model(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='input_layer')\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv2d_1')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2, name='leaky_relu_1')(x)\n",
    "    x = BatchNormalization(name='batch_norm_1')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), strides=2, padding='same', name='conv2d_2')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name='leaky_relu_2')(x)\n",
    "    x = BatchNormalization(name='batch_norm_2')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), strides=2, padding='same', name='conv2d_3')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name='leaky_relu_3')(x)\n",
    "    x = BatchNormalization(name='batch_norm_3')(x)\n",
    "    x = Dropout(0.4, name='dropout_1')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), strides=2, padding='same', name='conv2d_4')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name='leaky_relu_4')(x)\n",
    "    x = BatchNormalization(name='batch_norm_4')(x)\n",
    "    x = Dropout(0.4, name='dropout_2')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), strides=2, padding='same', name='conv2d_5')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name='leaky_relu_5')(x)\n",
    "    x = BatchNormalization(name='batch_norm_5')(x)\n",
    "    x = Dropout(0.4, name='dropout_3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(512, (3, 3), strides=2, padding='same', name='conv2d_transpose_1')(x)\n",
    "    x = ReLU(name='relu_1')(x)\n",
    "    x = BatchNormalization(name='batch_norm_6')(x)\n",
    "    x = Dropout(0.4, name='dropout_4')(x)\n",
    "\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=2, padding='same', name='conv2d_transpose_2')(x)\n",
    "    x = ReLU(name='relu_2')(x)\n",
    "    x = BatchNormalization(name='batch_norm_7')(x)\n",
    "    x = Dropout(0.4, name='dropout_5')(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same', name='conv2d_transpose_3')(x)\n",
    "    x = ReLU(name='relu_3')(x)\n",
    "    x = BatchNormalization(name='batch_norm_8')(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same', name='conv2d_transpose_4')(x)\n",
    "    x = ReLU(name='relu_4')(x)\n",
    "    x = BatchNormalization(name='batch_norm_9')(x)\n",
    "\n",
    "    outputs = Conv2D(3, (3, 3), padding='same', activation='sigmoid', name='output_layer')(x)\n",
    "    return Model(inputs, outputs, name=\"complex_diffusion_model\")\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "diffusion_model = build_complex_diffusion_model(input_shape)\n",
    "diffusion_model.summary()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "diffusion_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='mse')\n",
    "\n",
    "# 打印模型输入输出形状\n",
    "print(\"模型输入形状:\", diffusion_model.input_shape)\n",
    "print(\"模型输出形状:\", diffusion_model.output_shape)\n",
    "\n",
    "# 使用ImageDataGenerator加载数据\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2  # 设置验证集比例\n",
    ")\n",
    "\n",
    "# 生成训练数据，只从猫的目录中加载数据\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='training',  # 设置为训练数据\n",
    "    classes=['cats']  # 只加载cats文件夹\n",
    ")\n",
    "\n",
    "# 生成验证数据，只从猫的目录中加载数据\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    './DATA/train',  # 数据集路径\n",
    "    target_size=(64, 64),  # 调整图片大小\n",
    "    class_mode='input',  # 更改为 'input'\n",
    "    subset='validation',  # 设置为验证数据\n",
    "    classes=['cats']  # 只加载cats文件夹\n",
    ")\n",
    "\n",
    "# 检查生成器是否正确生成数据\n",
    "print(\"检查训练数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(train_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(\"检查验证数据生成器...\")\n",
    "for i in range(3):  # 检查前三个批次\n",
    "    batch = next(validation_generator)\n",
    "    if batch is None:\n",
    "        print(f\"批次 {i} 是 None\")\n",
    "    else:\n",
    "        print(f\"批次 {i} 形状: {batch[0].shape}, {batch[1].shape}\")\n",
    "\n",
    "print(f\"训练数据的batch size: {train_generator.batch_size}\")\n",
    "print(f\"验证数据的batch size: {validation_generator.batch_size}\")\n",
    "\n",
    "# 自定义回调函数以记录每一层的输出\n",
    "class LayerOutputLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, generator):\n",
    "        super(LayerOutputLogger, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.generator = generator\n",
    "        self.file_writers = {}\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super(LayerOutputLogger, self).set_model(model)\n",
    "        for layer in self.model.layers:\n",
    "            if 'conv' in layer.name or 'relu' in layer.name or 'batch_normalization' in layer.name:\n",
    "                self.file_writers[layer.name] = tf.summary.create_file_writer(os.path.join(self.log_dir, layer.name))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            x_batch, _ = next(self.generator)\n",
    "            sample = x_batch[0:1]  # 选择一个样本\n",
    "            for layer_name, file_writer in self.file_writers.items():\n",
    "                layer_model = Model(inputs=self.model.input, outputs=self.model.get_layer(layer_name).output)\n",
    "                feature_maps = layer_model.predict(sample)\n",
    "                with file_writer.as_default():\n",
    "                    for i in range(min(feature_maps.shape[-1], 3)):  # 只记录前三个特征图\n",
    "                        tf.summary.image(f\"{layer_name}_filter_{i}\", feature_maps[..., i:i+1], step=epoch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LayerOutputLogger on_epoch_end: {e}\")\n",
    "\n",
    "# 定义训练参数\n",
    "epochs = 100\n",
    "\n",
    "# 训练模型\n",
    "history = diffusion_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[tensorboard_callback, LayerOutputLogger(log_dir, train_generator)]\n",
    ")\n",
    "\n",
    "# 启动TensorBoard（在命令行中运行）\n",
    "# !tensorboard --logdir logs/fit\n",
    "\n",
    "# 生成新样本\n",
    "noise = np.random.normal(0, 1, (10, 64, 64, 3))\n",
    "generated_images = diffusion_model.predict(noise)\n",
    "\n",
    "# 显示生成的图像\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印训练历史\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
